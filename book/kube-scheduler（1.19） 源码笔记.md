# kube-schedulerï¼ˆ1.19ï¼‰ æºç ç¬”è®°

## SchedulingQueueä¸‰çº§è°ƒåº¦é˜Ÿåˆ—

![kube-scheduler-SchedulingQueue](../image/kube-scheduler-SchedulingQueue.png)

SchedulingQueue æ˜¯ä¸€ä¸ª Interfaceï¼Œ ä¸»è¦æä¾›ç”¨ä»¥å®žçŽ°å¯¹ Pod çš„å…¥é˜Ÿå‡ºé˜Ÿæ“ä½œï¼Œä¸Šå›¾ä¸­ `PodBackoffMap` å·²ç»è¢«æ›¿æ¢æˆ`QueuedPodInfo`ï¼Œ`QueuedPodInfo`å°†è´¯ç©¿äºŽæ•´ä¸ªä¸‰ä¸ªè°ƒåº¦é˜Ÿåˆ—ä¸­ã€‚

```go
// QueuedPodInfo is a Pod wrapper with additional information related to
// the pod's status in the scheduling queue, such as the timestamp when
// it's added to the queue.
type QueuedPodInfo struct {
   Pod *v1.Pod
   // The time pod added to the scheduling queue.
  // ä¸Šæ¬¡è¢«è°ƒåº¦çš„æ—¶é—´æˆ³
   Timestamp time.Time
   // Number of schedule attempts before successfully scheduled.
   // It's used to record the # attempts metric.
  // è°ƒåº¦æˆåŠŸä¹‹å‰é‡è¯•æ¬¡æ•°
   Attempts int
   // The time when the pod is added to the queue for the first time. The pod may be added
   // back to the queue multiple times before it's successfully scheduled.
   // It shouldn't be updated once initialized. It's used to record the e2e scheduling
   // latency for a pod.
  // podç¬¬ä¸€æ¬¡è¢«è°ƒåº¦çš„æ—¶é—´ï¼Œåœ¨è¢«åˆå§‹åŒ–ä¹‹åŽï¼Œè¯¥æ—¶é—´ä¸ä¼šè¢«æ›´æ–°ï¼Œä¸»è¦ç”¨äºŽè®¡ç®—è°ƒåº¦è€—æ—¶
   InitialAttemptTimestamp time.Time
}
```



```go
// SchedulingQueue is an interface for a queue to store pods waiting to be scheduled.
// The interface follows a pattern similar to cache.FIFO and cache.Heap and
// makes it easy to use those data structures as a SchedulingQueue.
type SchedulingQueue interface {
   framework.PodNominator
   Add(pod *v1.Pod) error
   // AddUnschedulableIfNotPresent adds an unschedulable pod back to scheduling queue.
   // The podSchedulingCycle represents the current scheduling cycle number which can be
   // returned by calling SchedulingCycle().
   AddUnschedulableIfNotPresent(pod *framework.QueuedPodInfo, podSchedulingCycle int64) error
   // SchedulingCycle returns the current number of scheduling cycle which is
   // cached by scheduling queue. Normally, incrementing this number whenever
   // a pod is popped (e.g. called Pop()) is enough.
   SchedulingCycle() int64
   // Pop removes the head of the queue and returns it. It blocks if the
   // queue is empty and waits until a new item is added to the queue.
   Pop() (*framework.QueuedPodInfo, error)
   Update(oldPod, newPod *v1.Pod) error
   Delete(pod *v1.Pod) error
   MoveAllToActiveOrBackoffQueue(event string)
   AssignedPodAdded(pod *v1.Pod)
   AssignedPodUpdated(pod *v1.Pod)
   PendingPods() []*v1.Pod
   // Close closes the SchedulingQueue so that the goroutine which is
   // waiting to pop items can exit gracefully.
   Close()
   // NumUnschedulablePods returns the number of unschedulable pods exist in the SchedulingQueue.
   NumUnschedulablePods() int
   // Run starts the goroutines managing the queue.
   Run()
}
```

å®žé™…ä¸»è¦é€šè¿‡ `PriorityQueue` æ¥å®žçŽ°è°ƒåº¦é˜Ÿåˆ—

```go
// PriorityQueue implements a scheduling queue.
// The head of PriorityQueue is the highest priority pending pod. This structure
// has three sub queues. One sub-queue holds pods that are being considered for
// scheduling. This is called activeQ and is a Heap. Another queue holds
// pods that are already tried and are determined to be unschedulable. The latter
// is called unschedulableQ. The third queue holds pods that are moved from
// unschedulable queues and will be moved to active queue when backoff are completed.
type PriorityQueue struct {
   // PodNominator abstracts the operations to maintain nominated Pods.
   framework.PodNominator

   stop  chan struct{}
   clock util.Clock

   // pod initial backoff duration.
   podInitialBackoffDuration time.Duration
   // pod maximum backoff duration.
   podMaxBackoffDuration time.Duration

   lock sync.RWMutex
   cond sync.Cond

   // activeQ is heap structure that scheduler actively looks at to find pods to
   // schedule. Head of heap is the highest priority pod.
   activeQ *heap.Heap
   // podBackoffQ is a heap ordered by backoff expiry. Pods which have completed backoff
   // are popped from this heap before the scheduler looks at activeQ
   podBackoffQ *heap.Heap
   // unschedulableQ holds pods that have been tried and determined unschedulable.
   unschedulableQ *UnschedulablePodsMap
   // schedulingCycle represents sequence number of scheduling cycle and is incremented
   // when a pod is popped.
   schedulingCycle int64
   // moveRequestCycle caches the sequence number of scheduling cycle when we
   // received a move request. Unscheduable pods in and before this scheduling
   // cycle will be put back to activeQueue if we were trying to schedule them
   // when we received move request.
   moveRequestCycle int64

   // closed indicates that the queue is closed.
   // It is mainly used to let Pop() exit its control loop while waiting for an item.
   closed bool
}
```

å…¶ä¸­åŒ…å«å¦‚ä¸‹ä¸‰çº§è°ƒåº¦é˜Ÿåˆ—ï¼š

- activeQï¼Œæ´»åŠ¨é˜Ÿåˆ—ï¼Œä¸»è¦ç”¨ä»¥å­˜å‚¨å½“å‰æ‰€æœ‰æ­£åœ¨ç­‰å¾…è°ƒåº¦çš„Pod
- unschedulableQï¼Œ ä¸å¯è°ƒåº¦é˜Ÿåˆ—ï¼Œå½“Podç”³è¯·çš„èµ„æºåœ¨å½“å‰é›†ç¾¤ä¸­æ— æ³•å¾—åˆ°æ»¡è¶³æ—¶ï¼Œå°†ä¼šè¢«è°ƒåº¦è‡³è¯¥é˜Ÿåˆ—ä¸­ï¼Œå½“é›†ç¾¤èµ„æºå‘ç”Ÿå˜åŒ–æ—¶ï¼Œå†æ¬¡å¯¹è¯¥é˜Ÿåˆ—è¿›è¡Œè°ƒåº¦å°è¯•
- podBackoffQï¼Œå¤±è´¥é˜Ÿåˆ—ï¼Œå½“podè°ƒåº¦å¤±è´¥ä¹‹åŽå°†ä¼šå¢žåŠ åˆ°è¯¥é˜Ÿåˆ—ï¼Œç­‰å¾…åŽç»­é‡è¯•ï¼Œåå¤è°ƒåº¦å¤±è´¥çš„Podå°†ä¼šæŒ‰æ­¤å¢žé•¿ç­‰å¾…æ—¶é—´ï¼Œé™ä½Žé‡è¯•æ•ˆçŽ‡ã€‚

podBackoffQ å’Œ unschedulableQï¼Œä¼šå®šæ—¶ä»Žå‰é¢ä¸¤ä¸ªé˜Ÿåˆ—ä¸­æ‹¿å‡ºPodæ”¾åˆ°activeQé˜Ÿåˆ—ã€‚

- æ¯éš”1ç§’æ‰§è¡Œ `flushBackoffQCompleted`ï¼ŒåŽ»æ‰¾åˆ°backoffQä¸­ç­‰å¾…åˆ°æœŸçš„Podï¼Œå°†å…¶æ”¾å…¥åˆ°activeQä¸­
- æ¯éš”30ç§’æ‰§è¡Œ `flushUnschedulableQLeftover`ï¼Œå¦‚æžœå½“å‰æ—¶é—´-podçš„æœ€åŽè°ƒåº¦æ—¶é—´å¤§äºŽ60s,å°±é‡æ–°è°ƒåº¦ï¼Œè½¬ç§»åˆ°podBackoffQæˆ–è€…activeQä¸­

### ActiveQ 

#### èµ„æºå‘ç”Ÿå˜åŒ–æ—¶

å½“æœ‰æ–° Pod è¢«åˆ›å»ºã€æˆ–è€…é›†ç¾¤èµ„æºå‘ç”Ÿå˜åŒ–æ—¶ï¼Œæ¯”å¦‚ Node èµ„æºä¿¡æ¯å‘ç”Ÿå˜åŒ–ï¼Œéœ€è¦å°†åŽŸæ¥ unschedulableQ é˜Ÿåˆ—ä¸­è°ƒåº¦å¤±è´¥çš„ Pod è¿›è¡Œé‡æ–°è°ƒåº¦ï¼Œæ­¤å¤„é‡æ–°è°ƒåº¦ä¸»è¦é€šè¿‡å°† unschedulableQ é˜Ÿåˆ—ä¸­ Pod æ·»åŠ åˆ° activeQ æˆ–è€… podBackoffQ é˜Ÿåˆ—ä¸­ï¼Œé€šè¿‡è°ƒç”¨`MoveAllToActiveOrBackoffQueue(event string)` æ–¹æ³•å®žçŽ°ã€‚

```go
// MoveAllToActiveOrBackoffQueue moves all pods from unschedulableQ to activeQ or backoffQ.
// This function adds all pods and then signals the condition variable to ensure that
// if Pop() is waiting for an item, it receives it after all the pods are in the
// queue and the head is the highest priority pod.
func (p *PriorityQueue) MoveAllToActiveOrBackoffQueue(event string) {
   p.lock.Lock()
   defer p.lock.Unlock()
  // åˆ›å»ºä¸Ž unschedulableQ ä¸­ Pod æ•°é‡ç›¸ç­‰çš„åˆ‡ç‰‡
   unschedulablePods := make([]*framework.QueuedPodInfo, 0, len(p.unschedulableQ.podInfoMap))
   for _, pInfo := range p.unschedulableQ.podInfoMap {
     // å°† unschedulableQ é˜Ÿåˆ—ä¸­æ‰€æœ‰å®¹å™¨å…¨éƒ¨æ·»åŠ åˆ°ä¸Šé¢åˆ›å»ºçš„åˆ‡ç‰‡ä¸­
      unschedulablePods = append(unschedulablePods, pInfo)
   }
  // å°† unschedulableQ ä¸­ Pod æŒ‰ç…§ä¸åŒç±»åž‹æ·»åŠ  activeQ æˆ–è€… podBackoffQ é˜Ÿåˆ—ä¸­
   p.movePodsToActiveOrBackoffQueue(unschedulablePods, event)
}

// NOTE: this function assumes lock has been acquired in caller
func (p *PriorityQueue) movePodsToActiveOrBackoffQueue(podInfoList []*framework.QueuedPodInfo, event string) {
   for _, pInfo := range podInfoList {
      pod := pInfo.Pod
     // åˆ¤æ–­å½“å‰ Pod ä»ç„¶å¤„äºŽ podBackoff é‡å¯é˜¶æ®µï¼Œåˆ™å°†è¯¥èŠ‚ç‚¹æ·»åŠ åˆ° podBackoffQ é˜Ÿåˆ—ä¸­
     // ä¸»è¦é€šè¿‡èŽ·å–å½“å‰ pod é‡è¯•æ¬¡æ•° * podInitialBackoffDurationï¼ˆé»˜è®¤1sï¼‰èŽ·å–ä¸‹æ¬¡é‡è¯•éœ€è¦ç­‰å¾…æ—¶é—´
     // å¦‚æžœðŸ‘†çš„ç­‰å¾…æ—¶é—´ > podMaxBackoffDuration(é»˜è®¤10s)ï¼Œåˆ™è¯¥ Pod ä¸‹æ¬¡é‡è¯•éœ€è¦ç­‰å¾…10s
     // èŽ·å–ä¸Šæ¬¡ Pod è°ƒåº¦æ—¶é—´ + ç­‰å¾…æ—¶é—´ï¼Œå¦‚æžœå‰é¢çš„æ—¶é—´å¤§äºŽå½“å‰æ—¶é—´ï¼Œåˆ™è¿”å›žtrueã€‚
      if p.isPodBackingoff(pInfo) {
        // å°†è¿˜æœªå®Œæˆé‡è¯•çš„ Pod ç»§ç»­æ·»åŠ åˆ° podBackoffQ é˜Ÿé¦–ï¼Œä¼˜å…ˆè¿›è¡ŒæŽ¨é€åˆ° activeQ é˜Ÿåˆ—ä¸­
         if err := p.podBackoffQ.Add(pInfo); err != nil {
            klog.Errorf("Error adding pod %v to the backoff queue: %v", pod.Name, err)
         } else {
            metrics.SchedulerQueueIncomingPods.WithLabelValues("backoff", event).Inc()
            p.unschedulableQ.delete(pod)
         }
      } else {
        // å¦‚æžœè¯¥ Pod å·²ç»åˆ°äº†é‡è¯•çš„æ—¶é—´ï¼Œåˆ™ç›´æŽ¥æŽ¨é€è‡³ activeQ é˜Ÿåˆ—ä¸­è¿›è¡Œä¸‹ä¸€æ¬¡è°ƒåº¦
         if err := p.activeQ.Add(pInfo); err != nil {
            klog.Errorf("Error adding pod %v to the scheduling queue: %v", pod.Name, err)
         } else {
            metrics.SchedulerQueueIncomingPods.WithLabelValues("active", event).Inc()
            p.unschedulableQ.delete(pod)
         }
      }
   }
   // moveRequestCycleç¼“å­˜schedulingCycle, å½“æœªè°ƒåº¦çš„podé‡æ–°è¢«æ·»åŠ åˆ°activeQueueä¸­
   // ä¼šä¿å­˜schedulingCycleåˆ°moveRequestCycleä¸­
   p.moveRequestCycle = p.schedulingCycle
   p.cond.Broadcast()
}
```

ActiveQåŠ å…¥æ“ä½œå¹²äº†å•¥å‘¢ï¼Ÿ

- ä¼šå°†PodåŠ å…¥åˆ°activeQï¼Œå¹¶ä¸”ä»ŽbackoffQå’Œ unschedulableQä¸­ç§»é™¤å½“å‰Pod
- åŒæ—¶é€šè¿‡`sync.cond`å¹¿æ’­é€šçŸ¥é˜»å¡žåœ¨Popæ“ä½œçš„schedulerèŽ·å–æ–°çš„Pod

```go
// Add adds a pod to the active queue. It should be called only when a new pod
// is added so there is no chance the pod is already in active/unschedulable/backoff queues
func (p *PriorityQueue) Add(pod *v1.Pod) error {
   p.lock.Lock()
   defer p.lock.Unlock()
  // æ–°å»º QueuedPodInfo å¯¹è±¡
   pInfo := p.newQueuedPodInfo(pod)
  // å°†ä¸Šè¿° Pod æ·»åŠ åˆ° activeQ
  // å¦‚æžœ activeQ ä¸­å·²ç»å­˜åœ¨è¯¥ Pod åˆ™æ›´æ–°ï¼Œä¸å­˜åœ¨åˆ™ç›´æŽ¥æ·»åŠ 
   if err := p.activeQ.Add(pInfo); err != nil {
      klog.Errorf("Error adding pod %v to the scheduling queue: %v", nsNameForPod(pod), err)
      return err
   }
  // ä»Ž unschedulableQ ä¸­åˆ é™¤è¯¥ Pod ä¿¡æ¯ï¼Œé˜²æ­¢äºŒæ¬¡è°ƒåº¦
   if p.unschedulableQ.get(pod) != nil {
      klog.Errorf("Error: pod %v is already in the unschedulable queue.", nsNameForPod(pod))
      p.unschedulableQ.delete(pod)
   }
  // ä»Ž podBackoffQ ä¸­åˆ é™¤è¯¥ Pod ä¿¡æ¯ï¼Œé˜²æ­¢äºŒæ¬¡è°ƒåº¦
   // Delete pod from backoffQ if it is backing off
   if err := p.podBackoffQ.Delete(pInfo); err == nil {
      klog.Errorf("Error: pod %v is already in the podBackoff queue.", nsNameForPod(pod))
   }
   metrics.SchedulerQueueIncomingPods.WithLabelValues("active", PodAdd).Inc()
  // å­˜å‚¨ Pod å’Œè¢«æå Nodeï¼Œæ­¤å¤„åˆšåˆšå¼€å§‹è°ƒåº¦ï¼Œæ‰€ä»¥ Node åç§°æ˜¯ç©º
   p.PodNominator.AddNominatedPod(pod, "")
  // å¹¿æ’­é€šçŸ¥æ‰€æœ‰æºç¨‹ï¼Œæœ‰æ–° pod æ·»åŠ ï¼Œå‡†å¤‡å¯¹è¯¥ Pod è¿›è¡Œé¢„é€‰å’Œä¼˜é€‰è¿‡æ»¤
   p.cond.Broadcast()

   return nil
}
```

å¦‚æžœè°ƒåº¦å¤±è´¥ä¹‹åŽï¼Œéœ€è¦å¯¹è°ƒåº¦å¤±è´¥ Pod è¿›è¡Œåˆ†æµåˆ°å…¶ä»–ä¸¤ä¸ªé˜Ÿåˆ—ä¸­ï¼Œä½†æ˜¯åº”è¯¥æ”¾åˆ° unschedulableQ è¿˜æ˜¯ podBackoffQï¼Ÿ

```go
// AddUnschedulableIfNotPresent inserts a pod that cannot be scheduled into
// the queue, unless it is already in the queue. Normally, PriorityQueue puts
// unschedulable pods in `unschedulableQ`. But if there has been a recent move
// request, then the pod is put in `podBackoffQ`.
func (p *PriorityQueue) AddUnschedulableIfNotPresent(pInfo *framework.QueuedPodInfo, podSchedulingCycle int64) error {
	p.lock.Lock()
	defer p.lock.Unlock()
	pod := pInfo.Pod
  // å¦‚æžœ unschedulableQ å·²ç»å­˜åœ¨è¯¥ Podï¼Œåˆ™è¿”å›ž
	if p.unschedulableQ.get(pod) != nil {
		return fmt.Errorf("pod: %v is already present in unschedulable queue", nsNameForPod(pod))
	}

	// Refresh the timestamp since the pod is re-added.
	pInfo.Timestamp = p.clock.Now()
  // å¦‚æžœ activeQ å·²ç»å­˜åœ¨è¯¥ Podï¼Œåˆ™è¿”å›ž
	if _, exists, _ := p.activeQ.Get(pInfo); exists {
		return fmt.Errorf("pod: %v is already present in the active queue", nsNameForPod(pod))
	}
  // // å¦‚æžœ podBackoffQ å·²ç»å­˜åœ¨è¯¥ Podï¼Œåˆ™è¿”å›ž
	if _, exists, _ := p.podBackoffQ.Get(pInfo); exists {
		return fmt.Errorf("pod %v is already present in the backoff queue", nsNameForPod(pod))
	}

	// If a move request has been received, move it to the BackoffQ, otherwise move
	// it to unschedulableQ.
  // å¦‚æžœå½“å‰é›†ç¾¤èŠ‚ç‚¹èµ„æºå‘ç”Ÿå˜åŒ–ç­‰æƒ…å†µå‡ºçŽ°ï¼Œåˆ™å°† Pod ç§»åŠ¨åˆ° podBackoffQ
	if p.moveRequestCycle >= podSchedulingCycle {
		if err := p.podBackoffQ.Add(pInfo); err != nil {
			return fmt.Errorf("error adding pod %v to the backoff queue: %v", pod.Name, err)
		}
		metrics.SchedulerQueueIncomingPods.WithLabelValues("backoff", ScheduleAttemptFailure).Inc()
	} else {
    // å¦åˆ™ç§»åŠ¨åˆ° unschedulableQ
		p.unschedulableQ.addOrUpdate(pInfo)
		metrics.SchedulerQueueIncomingPods.WithLabelValues("unschedulable", ScheduleAttemptFailure).Inc()
	}

  // é‡ç½® NominatedPod ä¿¡æ¯
	p.PodNominator.AddNominatedPod(pod, "")
	return nil
}
```

ä¸€èˆ¬æ¥è¯´ï¼Œå½“ä¸€ä¸ªPodä¸èƒ½å¤Ÿè¢«è°ƒåº¦çš„æ—¶å€™ï¼Œå®ƒä¼šè¢«æ”¾åˆ° unschedulableQ ä¸­ï¼Œä½†æ˜¯å¦‚æžœæ”¶åˆ°äº†ä¸€ä¸ª`Move Request`ï¼Œé‚£ä¹ˆå°±å°†è¿™ä¸ªPodç§»åˆ°BackoffQã€‚è¿™æ˜¯å› ä¸ºæœ€è¿‘é›†ç¾¤èµ„æºå‘ç”Ÿäº†å˜æ›´ï¼Œå¦‚æžœæ”¾åˆ° podBackoffQï¼Œä¼šæ›´å¿«çš„è¿›è¡Œå°è¯•è¿™ä¸ªPodï¼Œæ›´å¿«åœ°ä½¿å®ƒå¾—åˆ°è°ƒåº¦ï¼Œä¸»è¦æ˜¯å› ä¸º podBackoffQ ä¼šæ›´å¿«è¢«æ›´æ–°åˆ° activeQ è¿›è¡Œè°ƒåº¦ã€‚

### PodBackoffQ

podBackoffQä¸»è¦å­˜å‚¨é‚£äº›åœ¨å¤šä¸ªschedulingCycleä¸­ä¾æ—§è°ƒåº¦å¤±è´¥çš„æƒ…å†µä¸‹ï¼Œåˆ™ä¼šé€šè¿‡ä¹‹å‰è¯´çš„backOffæœºåˆ¶ï¼Œå»¶è¿Ÿç­‰å¾…è°ƒåº¦çš„æ—¶é—´ã€‚åŒæ—¶ä¹Ÿæ˜¯ä¸€ä¸ªå †ï¼Œæ¯æ¬¡èŽ·å–å †é¡¶çš„å…ƒç´ ï¼ŒæŸ¥çœ‹æ˜¯å¦åˆ°æœŸï¼Œå¦‚æžœåˆ°æœŸåˆ™å°†å…¶Popå‡ºæ¥ï¼ŒåŠ å…¥åˆ°activeQä¸­ã€‚

```go
// flushBackoffQCompleted Moves all pods from backoffQ which have completed backoff in to activeQ
func (p *PriorityQueue) flushBackoffQCompleted() {
   p.lock.Lock()
   defer p.lock.Unlock()
   for {
     // èŽ·å–å½“å‰ podBackoffQ å †é¡¶çš„ Pod
      rawPodInfo := p.podBackoffQ.Peek()
      if rawPodInfo == nil {
         return
      }
      pod := rawPodInfo.(*framework.QueuedPodInfo).Pod
     // èŽ·å–å½“å‰ Pod çš„åˆ°æœŸæ—¶é—´ï¼Œå¦‚æžœæœªåˆ°æœŸåˆ™è¿”å›ž
      boTime := p.getBackoffTime(rawPodInfo.(*framework.QueuedPodInfo))
      if boTime.After(p.clock.Now()) {
         return
      }
     // å¦‚æžœæ—¶é—´åˆ°æœŸåˆ™ä»Ž podBackoffQ å¼¹å‡ºè¯¥ Pod
      _, err := p.podBackoffQ.Pop()
      if err != nil {
         klog.Errorf("Unable to pop pod %v from backoff queue despite backoff completion.", nsNameForPod(pod))
         return
      }
     // å°†è¯¥ Pod æ·»åŠ åˆ° activeQ 
      p.activeQ.Add(rawPodInfo)
      metrics.SchedulerQueueIncomingPods.WithLabelValues("active", BackoffComplete).Inc()
     // é€šçŸ¥å„åç¨‹æœ‰æ–° Pod åŠ å…¥
      defer p.cond.Broadcast()
   }
}
```

###UnschedulableQ

unschedulableQ å­˜å‚¨å·²ç»å°è¯•è°ƒåº¦ä½†æ˜¯å½“å‰é›†ç¾¤èµ„æºä¸æ»¡è¶³çš„podçš„é˜Ÿåˆ—ï¼Œå¦‚æžœå½“å‰æ—¶é—´-podçš„æœ€åŽè°ƒåº¦æ—¶é—´å¤§äºŽ60sï¼Œå°±é‡æ–°è°ƒåº¦ï¼Œè½¬ç§»åˆ°podBackoffQæˆ–è€…activeQä¸­ã€‚

```go
// flushUnschedulableQLeftover moves pod which stays in unschedulableQ longer than the unschedulableQTimeInterval
// to activeQ.
func (p *PriorityQueue) flushUnschedulableQLeftover() {
   p.lock.Lock()
   defer p.lock.Unlock()

   var podsToMove []*framework.QueuedPodInfo
   currentTime := p.clock.Now()
   for _, pInfo := range p.unschedulableQ.podInfoMap {
      lastScheduleTime := pInfo.Timestamp
     // å¦‚æžœè¯¥ pod 1åˆ†é’Ÿå†…æ²¡æœ‰è¢«è°ƒåº¦å°±åŠ å…¥åˆ° podsToMove
      if currentTime.Sub(lastScheduleTime) > unschedulableQTimeInterval {
         podsToMove = append(podsToMove, pInfo)
      }
   }

   if len(podsToMove) > 0 {
     // podsToMoveå°†è¿™äº›podç§»åŠ¨åˆ°activeQ
      p.movePodsToActiveOrBackoffQueue(podsToMove, UnschedulableTimeout)
   }
}
```

